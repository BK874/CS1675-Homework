
<!-- saved from url=(0057)https://people.cs.pitt.edu/~kovashka/cs1675_fa18/hw5.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CS1675: Homework 5 </title>
</head>
<body>
<h2>CS1675: Homework 5 </h2>
<b>Due:</b> 10/16/2018 (Fall Break), 11:59pm 
<br><br>

This assignment is worth 30 points. 
<br><br><br>

You will trace through a run of the perceptron algorithm. 
<br><br>
You have the following two-dimensional data: {(-1,-4), (-3,-1), (-3,-2), (-2,1), (-1,-1), (4,5), (1,3), (4,0), (3,2), (5,3)}. The first five data points belong to the positive class, and the second set of five to the negative class. This data is linearly separable and can be plotted in 2D using its two feature dimensions. Your goal is to create figures similar to Figure 4.7 in Bishop.
<br><br>
Instead of a basis function, you will just use <b>x</b>, i.e. φ(<b>x</b>) = <b>x</b>.  
<br><br>

In a script <font face="courier new">perceptron.m</font>, implement the perceptron algorithm and use it, along with some provided plotting code, to trace through several iterations of the method:
<ol>
<li>[5 pts] First, represent the data and labels, with samples as the rows and features (coordinates) as the columns. Use all the data for training since we won't test but will only visualize what the method is learning. Set the learning rate <i>η</i> to 0.1. Initialize the weight vector to a vector of random numbers.</li>
<li>[5 pts] Compute the predicted label vector <font face="courier new">Y_pred</font> by multiplying the weights and features, and checking the sign of the result. Use the Matlab function <font face="courier new">sign</font>. If the predicted label is 0, set it to 1.</li>
<li>[5 pts] Compute the accuracy of the current prediction for each training sample. While the accuracy for some sample is not 1, loop as follows. </li>
<li>[5 pts] Find a sample whose label isn't accurately predicted. If there are multiple such samples, choose at random. Compute the weight update for that misclassified sample. Then predict all labels again using the new weights, and check the accuracy. </li>
<li>[5 pts] Use the provided <font face="courier new"><a href="https://people.cs.pitt.edu/~kovashka/cs1675_fa18/plot_points_w.m">plot_points_w.m</a></font> function to plot the data points and the direction of the weight vector. This function shows positive samples as open circles, and negative samples as filled circles. It shows correctly classified samples in green, and misclassified samples in red. It also outputs the iteration ID and the two feature dimensions for the misclassified example that is being used to correct <b>w</b>. This script requires that you keep an iteration counter <font face="courier new">ct</font> and an index for which misclassified point was selected in a given iteration as <font face="courier new">sel</font>. Name your weights vector variable <font face="courier new">w</font>, your data matrix <font face="courier new">X</font> (with samples as the rows), your vector of true labels <font face="courier new">Y</font>, and your predicted labels <font face="courier new">Y_pred</font>. </li>
<li>[5 pts] In a file <font face="courier new">report.pdf/docx</font>, show the process for three consecutive iterations of the method, i.e. include three figures output by the plotting function provided. If too many (or too few) iterations are taking place, terminate the run and start another run.</li>
</ol>


<!--<u>Part II: Short answers about support vector machines</u> (30 points) 
<br><br>
Please provide your responses in the report file.
<ol>
<li>[5 pts] Bishop Exercise 6.3. Hints: Expand the norm notation, remembering that the L2 norm of a vector <b>x</b> is <b>x</b><sup>T</sup><b>x</b>, that <b>x</b><sup>T</sup><b>x</b> is the same as an inner product of <b>x</b> with itself, and transpose distribution properties. Then express the expanded form with kernel notation (what type of kernel do you see?)</li>
<li>[5 pts] Bishop Exercise 7.2.</li>
<li>[10 pts] Bishop Exercise 7.3. Hints: This is a two-class problem. You have two constraints total, one for the positive instance and one for the negative instance, and these constraints are equalities because your positive and negative points have to lie on the margin and be support vectors. Use Lagrange multipliers to make the constraints part of the optimization problem and find what <b>w</b> and b equal.</li>
<li>[10 pts] Examine the Matlab function <a href="https://www.mathworks.com/help/optim/ug/quadprog.html"><font face="courier new">quadprog</font></a>. It can be used train an SVM (find the optimal <b>w</b>). Consider the input variables <font face="courier new">H,f,A,b,Aeq,beq,lb,ub</font>. How should you set each of them so that the quadratic program that is solved is the solution to an SVM? How would you compute the weight vector <b>w</b> from the output of <font face="courier new">quadprog</font>?</li>
</ol>-->


<br>
<b>Submission:</b> Please include the following files:
<ul>
<li><font face="courier new">perceptron.m</font></li>
<li><font face="courier new">report.pdf/docx</font></li>
</ul>



<div id="UMS_TOOLTIP" style="position: absolute; cursor: pointer; z-index: 2147483647; background: transparent; top: -100000px; left: -100000px;"></div></body><umsdataelement id="UMSSendDataEventElement"></umsdataelement></html>